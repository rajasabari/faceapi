<!DOCTYPE html>
<html>

<head>
    <title>Speech Recognition</title>
</head>
<body>

    <div>
        Status: <span id="detection_status">No speech detected</span>
    </div>

    <script>
        // Check browser compatibility
        var count = 1
        if ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window) {
            // Create SpeechRecognition object
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            const recognition = new SpeechRecognition();
            const recognitionta = new SpeechRecognition();

            // Set recognition parameters
            recognition.lang = 'en-US'; // Language for speech recognition (e.g., English)
            recognitionta.lang = 'ta-IN'; // Language for speech recognition (e.g., Tamil)

            let isRecognitionRunning = false; // Track the status of recognition
            let isRecognitiontaRunning = false; // Track the status of recognitionta

            // Set recognition parameters
            // recognition.lang = 'ta,ml,kn'; // Language for speech recognition
            // Create AudioContext and AnalyzerNode for pitch detection
            let audioContext;
            let analyser;

            // Event fired when speech recognition starts
            // recognition.onstart = () => {
            //     // console.log('Speech recognition started');
            // };

              // Event fired when speech recognition results are available
            recognition.onresult = (event) => {
                const transcript = event.results[event.results.length - 1][0].transcript;
                var detectionStatusElement = document.getElementById('detection_status');
                detectionStatusElement.innerHTML = 'English Speech detected - ' + count++ + ' times';
                console.log('English Speech detected');
                recognition.stop()
            };

            recognitionta.onresult = (event) => {
                const transcript = event.results[event.results.length - 1][0].transcript;
                var detectionStatusElement = document.getElementById('detection_status');
                detectionStatusElement.innerHTML = 'Tamil Speech detected - ' + count++ + ' times';
                console.log('Tamil Speech detected');
                recognitionta.stop()

            };

            // Event fired when speech recognition ends
            recognition.onend = () => {
                console.log('English Speech recognition ended');
                isRecognitionRunning = false;
                startRecognitionOnPitchThreshold('en')
                
            };

            recognitionta.onend = () => {
                console.log('Tamil Speech recognition ended');
                isRecognitiontaRunning = false;
                startRecognitionOnPitchThreshold('ta')

            };

            // Event fired when an error occurs
            recognition.onerror = (event) => {
                var detectionStatusElement = document.getElementById('detection_status');
                detectionStatusElement.innerHTML = event.error;
                console.log('English Speech recognition error:', event.error);
            };

            recognitionta.onerror = (event) => {
                var detectionStatusElement = document.getElementById('detection_status');
                detectionStatusElement.innerHTML = event.error;
                console.log('Tamil Speech recognition error:', event.error);
            };

            // Start pitch detection and speech recognition when the pitch threshold is reached
            function startRecognitionOnPitchThreshold(value) {
                // Access the user's microphone
                navigator.mediaDevices.getUserMedia({ audio: true })
                    .then((stream) => {
                        // Create the AudioContext and AnalyzerNode after a user gesture
                        const startAudioContext = () => {
                            audioContext = new (window.AudioContext || window.webkitAudioContext)();
                            analyser = audioContext.createAnalyser();

                            // Set up pitch detection parameters
                            analyser.fftSize = 2048;
                            const bufferLength = analyser.fftSize;
                            const frequencyData = new Float32Array(bufferLength);

                            // Connect the microphone audio stream to the analyzer node
                            const microphone = audioContext.createMediaStreamSource(stream);
                            microphone.connect(analyser);

                            let isRecognitionRunning = false; // Track the status of speech recognition
                            // Start the pitch detection loop
                                analyser.getFloatTimeDomainData(frequencyData);
                                // Calculate the average pitch value
                                const averagePitch = frequencyData.reduce((sum, value) => sum + value, 0) / bufferLength;

                                const pitchThreshold = 0.1;

                            try {
                                if (!isRecognitionRunning && (value == 'all' || value == 'en')) {
                                    console.log('en')
                                    recognition.start();
                                    isRecognitionRunning = true;
                                    console.log('English Speech recognition started');
                                } else if (averagePitch < pitchThreshold && isRecognitionRunning) {
                                    console.log('here')
                                    // recognition.stop();
                                    isRecognitionRunning = false;
                                    // console.log('English Speech recognition stopped');
                                }

                                if (!isRecognitiontaRunning && (value == 'all' || value == 'ta')) {
                                    console.log('ta')
                                    recognitionta.start();
                                    isRecognitiontaRunning = true;
                                    console.log('Tamil Speech recognition started');
                                } else if (averagePitch < pitchThreshold && isRecognitiontaRunning) {
                                    // recognitionta.stop();
                                    isRecognitiontaRunning = false;
                                    // console.log('Tamil Speech recognition stopped');
                                }
                            } catch (error) {
                                console.log(error);
                            }
                               
                        };
                       
                        startAudioContext()
                    })
                    .catch((error) => {
                        console.error('Error accessing microphone:', error);
                    });
            }
            // Call the function to start pitch detection and speech recognition
            // setInterval (function () { startRecognitionOnPitchThreshold() }, 1000);

            startRecognitionOnPitchThreshold('all');
           
        } else {
            console.error('Speech recognition not supported in this browser');
        }
    </script>
</body>

</html>