<!DOCTYPE html>
<html>

<head>
    <title>Speech Recognition</title>
</head>
<body>

    <div>
        Status: <span id="detection_status">No speech detected</span>
    </div>

    <script>
        // Define the supported languages and their recognition objects
        const supportedLanguages = {
            'en': 'English',
            'ta': 'Tamil',
            'ml': 'Malayalam',
            'hi': 'Hindi',
            'kn': 'Kannada',
            'te': 'Telugu'
        };

        // Check browser compatibility
        if ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window) {
            const recognitionObjects = {};

            // Create recognition objects for each language
            for (const langCode in supportedLanguages) {
                recognitionObjects[langCode] = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
                recognitionObjects[langCode].lang = langCode;
            }

            // Create AudioContext and AnalyzerNode for pitch detection
            let audioContext;
            let analyser;
            let isRecognitionRunning = false;

            // Event fired when speech recognition results are available
            for (const langCode in recognitionObjects) {
                recognitionObjects[langCode].onresult = (event) => {
                    const transcript = event.results[event.results.length - 1][0].transcript;
                    const languageName = detectLanguage(transcript); // Detect language
                    updateDetectionStatus(`Human Speech detected ${languageName} - ${transcript}`);
                    console.log('Human Speech detected');
                };

                recognitionObjects[langCode].onend = () => {
                    startRecognitionOnPitchThreshold();
                };
            }

            // Event fired when an error occurs
            for (const langCode in recognitionObjects) {
                recognitionObjects[langCode].onerror = (event) => {
                    updateDetectionStatus(`Speech recognition error: ${event.error}`);
                    console.error('Speech recognition error:', event.error);
                };
            }

            // Function to detect the language of a given text
            function detectLanguage(text) {
                const detectedLang = window.langdetect.detect(text);
                if (detectedLang && detectedLang[0] && detectedLang[0][0]) {
                    return detectedLang[0][0];
                }
                return 'Unknown';
            }

            // Start pitch detection and speech recognition when the pitch threshold is reached
            function startRecognitionOnPitchThreshold() {
                // Access the user's microphone
                navigator.mediaDevices.getUserMedia({ audio: true })
                    .then((stream) => {
                        // Create the AudioContext and AnalyzerNode after a user gesture
                        const startAudioContext = () => {
                            audioContext = new (window.AudioContext || window.webkitAudioContext)();
                            analyser = audioContext.createAnalyser();
                            analyser.fftSize = 2048;

                            const bufferLength = analyser.fftSize;
                            const frequencyData = new Float32Array(bufferLength);

                            // Connect the microphone audio stream to the analyzer node
                            const microphone = audioContext.createMediaStreamSource(stream);
                            microphone.connect(analyser);

                            // Start the pitch detection loop
                            // setInterval(() => {
                            analyser.getFloatTimeDomainData(frequencyData);
                            const averagePitch = frequencyData.reduce((sum, value) => sum + value, 0) / bufferLength;
                            const pitchThreshold = 0.1;

                            if (!isRecognitionRunning) {
                                for (const langCode in recognitionObjects) {
                                    recognitionObjects[langCode].start();
                                }
                                isRecognitionRunning = true;
                            } else if (averagePitch >= pitchThreshold && isRecognitionRunning) {
                                isRecognitionRunning = false;
                                console.log('Speech recognition stopped');
                            }
                            // }, 1000); // Adjust the interval as needed
                        };

                        startAudioContext();
                    })
                    .catch((error) => {
                        updateDetectionStatus(`Error accessing microphone: ${error}`);
                        console.error('Error accessing microphone:', error);
                    });
            }

            // Function to update the detection status
            function updateDetectionStatus(message) {
                const detectionStatusElement = document.getElementById('detection_status');
                detectionStatusElement.innerHTML = message;
            }

            // Call the function to start pitch detection and speech recognition
            startRecognitionOnPitchThreshold();
        } else {
            console.error('Speech recognition not supported in this browser');
        }
    </script>
</body>

</html>
